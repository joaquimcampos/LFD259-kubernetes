## General

# Set
alias -g do="--dry-run=client -o yaml"
alias k=kubectl

## All API resource
kubectl api-resources

## Get several resources
kubectl get pod,svc,deploy

## Apply
kubectl apply -f [resource].yaml
kubectl create -f [resource].yaml
kubectl replace -f [resource].yaml

## Info
kubectl explain [resource]
kubectl explain [resource].spec | grep "<"
kubectl explain pod.spec | grep -e "-required-"
kubectl explain [resource].spec --recursive

## Get, Describe
kubectl get [resource]
kubectl get [resource] [name]
kubectl get [resource] -n [namespace]
kubectl get [resource] --all-namespaces
kubectl get [resource] -o yaml
kubectl get [resource] -o yaml > resource.yaml
kubectl get [resource] -o wide
kubectl -n [namespace] get -l [app=examplepod] [pod]
kubectl describe [resource] [name]
kubectl get events

## Set
kubectl set --help

## Edit
kubectl edit [resource] [name]

## Delete
kubectl delete resource name

## Metrics, Memory and CPU
kubectl top pod [pod-name]

# memory usage
kubectl exec -it [pod-name] -n [namespace] -- sh
top       # shows CPU and memory usage in real time
free -m   # shows memory usage

# ssh into worker node
crictl ps | grep [pod-name]
sudo crictl stats [pod-name]

## Resources
pod
svc
taint
deploy
rs (replicaset)
ep (endpoints)

## Security and Roles
kubectl create role  # creates Role defining permissions within a single namespace
kubectl create clusterrole
kubectl create rolebinding  # grants a Role or ClusterRole within a specific namespace
kubectl create clusterrolebinding  # grants a ClusterRole across the entire cluster
kubectl auth reconcile
# combination of user name, cluster name, authinfo, and possibly namespace
kubectl config get-contexts 

cat /etc/passwd # see users

kubectl get sa  [--all-namespaces] # serviceaccounts
kubectl get pod [mypod] -o yaml | grep serviceAccount
kubectl get clusterroles
kubectl get rolebindings

kubectl create serviceaccount [serviceaccount]
# Create token for serviceaccount
kubectl create token serviceaccount > /tmp/securitytoken

# Examples
kubectl create role pod-reader \
  --verb=get,list \
  --resource=pods \
  --namespace=default

kubectl create rolebinding read-pods \
  --role=pod-reader \
  --serviceaccount=default:myapp

## Services and Network
kubectl get svc [svc] -o yaml

# check if service is reaching pod
kubectl get endpoints [svc]
kubectl get pod -o wide
curl [svc-IP]:port
kubectl run tmp --rm -it --restart=Never --image=busybox -- wget -qO- [nginx-svc]
kubectl create svc clusterip foo --tcp=6262:8080 dro

curl ifconfig.io  # get node/container ip address

# expose pods and deployments
kubectl run nginx --image=nginx --port=80 --expose=true
# `kubectl expose` automatically chooses --selector based on pod labels
kubectl expose deployment/nginx --port=80 --type=NodePort
kubectl expose pod [mypod] --type=NodePort --port=80
kubectl expose deploy foo --port=6262 --target-port=8080
# Need to explicitly add --selector, but more flexible (e.g. set node port, etc.)
kubectl create service nodeport [mypod] --tcp=80

# network policy test
kubectl run busybox --image=busybox --rm -it --restart=Never \
  --labels=access=granted \
  -- wget -O- http://nginx:80 --timeout 2  # This should be fine

# test connection to outside from inside container
nc -vz 127.0.0.1 80
nc -vz www.linux.com 80

# DNS
nslookup [mypod]
nslookup [IP]  # find FQDN of object with IP (needed for across-node lookups)

# FQDN for "shopping" pod in "multitenant" namespace
shopping.multitenant.svc.cluster.local
wget -O - shopping.multitenant # wget and write to stdout

# ingress and service mesh
# Linkerd: pay attention to an object: inject annotations
kubectl -n multitenant get deploy mainapp -o yaml | \
  linkerd inject - | kubectl apply -f -

## Helm & Ingress
helm ls -n [namespace] # list releases
helm get values [release]
helm show values [chart]

helm create chart-test ## this would create a helm 
# run a helm chart and override default values
helm install -f myvalues.yaml myredis ./redis 
helm list --pending -A  # Find pending Helm deployments on all namespaces
helm uninstall [-n namespace] mychart  # uninstall a helm release
helm upgrade -f myvalues.yaml -f override.yaml redis ./redis  # upgrading a helm chart

helm search hub ingress
helm search hub ingress -o yaml | grep nginx
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm search repo ingress-nginx
helm pull ingress-nginx/ingress-nginx --untar
# helm repo add [NAME] [URL] [flags]
# helm repo update [REPO1] [flags]
# helm repo index [DIR] [flags]
# helm repo remove [REPO1] [flags]
# helm repo list

cd ingress-nginx
vim values.yaml  # can change Kind to DaemonSet
helm install myingress .

helm show values ingress-nginx/ingress-nginx
helm install mynode bitnami/node --set replicaCount=5

kubectl --namespace default get services -o wide myingress-ingress-nginx-controller
kubectl get ing --all-namespaces
curl -H "Host: www.example.com" http://10.104.227.79

kubectl get ds myingress-ingress-nginx-controller -o yaml | \
  linkerd inject --ingress - | kubectl apply -f -

## Kustomize
kubectl apply -k overlay-folder/

## Pods
kubectl run [pod] --image=[image] --labels="app=nginx" -n [namespace] [--port 80]
kubectl run [pod] --image=nginx --labels="app=nginx" --dry-run=client -o yaml > nginx-pod.yaml
kubectl run [pod] --image=busybox --restart=Never --env="var1=val1" --rm -it --dry-run=client -o yaml -- sleep 500

kubectl set image pod/nginx nginx=nginx:1.24.0
kubectl label po -l "app in (v1,v2)" tier=frontend
kubectl annotate po [pod] owner=marketing
kubectl annotate po -l app=v1 owner-  # remove annotation owner
kubectl annotate po nginx{1..3} description='my description'
kubectl annotate pod nginx1 --list  # check annotations for pod1

kubectl delete pod nginx{1..3}
kubectl delete po busybox --force --grace-period=0

kubect get po -o wide  # get pod IP
kubectl get po --label-columns=app  # show a column with the APP labels
kubectl get pod [pod] --show-labels -w  # -w = watch
kubectl exec [-it] [pod] -c [container] -- /bin/bash
kubectl exec [-it] [pod] -c [container] -- /bin/bash -c [cmd]
kubectl exec [pod] -c [container] -- ls /path

# describe all pods whose livenessProbe failed
kubectl get pod -o name | \
  xargs -i{} sh -c "kubectl describe {} | grep -q 'failed liveness probe' && echo {} "

## Deployment and Rollouts
kubectl create deployment <Deploy-Name>Â --image=<repo>/<app-name>:<version> --port 80 -r 1 -o yaml --dry-run=true > deploy.yaml  # -r = --replicas

kubectl create deploy busy --image=busybox [-o yaml] [--dry-run=client] -- sleep 3600
kubectl create deploy foo --image=dgkanatsios/simpleapp --port=8080 --replicas=3
kubectl get rs -l app=nginx-deploy -o yaml  # rs = replicaset
kubectl set image deploy nginx nginx=nginx:1.18.0
kubectl edit deploy nginx

# this automatically assigns label app=my-deploy and selector: matchLabels: app: my-deploy
kubectl create deploy [my-deploy] --image=[nginx] -o yaml 
kubectl scale deploy/[my-deploy] --replicas=4
kubectl autoscale deploy nginx --min=5 --max=10 --cpu-percent=80

# rollouts
kubectl rollout history deployment/[mydeploy]
kubectl rollout status deploy [mydeploy]
kubectl rollout undo [mydeploy] [--dry-run=client]
kubectl rollout undo [mydeploy] --to-revision=2
kubectl rollout pause deployment nginx

# View differences between revisions
kubectl rollout history deployment try1 --revision=1 > one.out
kubectl rollout history deployment try1 --revision=2 > two.out
kubectl rollout history deployment try1 --revision=5 -o yaml  # get yaml
diff one.out two.out  # shows version difference

# record changes and check
kubectl set image deploy [mydeploy] [myapp]=[myapp:2.9] --record=true
kubectl edit deploy [mydeploy] --record=true
kubectl get deploy [mydeploy] -o yaml

# DaemonSet (runs on each node, unlike Deployment)
kubectl get ds

## Nodes
kubectl get nodes -o wide
kubectl describe nodes  # allows you to check CPU and memory
kubectl top nodes  # check CPU and memory utilization

## ConfigMaps and Secrets

# ConfigMaps
kubectl create configmap mycm \
  --from-literal="foo=lala" --from-literal="foo2=lolo"
kubectl create configmap [colors] \
  --from-literal=[text=black] \
  --from-file=[./favorite] \
  --from-file=[./primary/]
kubectl get cm [colors] -o yaml
kubectl describe cm [colors]

# Secrets
kubectl get secrets
kubectl create secret generic --help
kubectl create secret generic mysql --from-literal=password=root
echo password | base64
echo YWRtaW4= | base64 -d


# check if the configmap/secret as env variables
kubectl exec [pod] -- env
kubectl exec [pod] -- echo $[ilike]

# check the configmap/secret mounted as a volume
kubectl exec -ti [pod] -- cat /path/[key to secret/cm]

## Namespaces
kubectl create namespace [ns]
kubectl get namespaces
kubectl config get-contexts
kubectl config set-context --current --namespace=my-namespace
kubectl config kubectl config use-context dev-context

## Jobs
kubectl get job [job] -o yaml
kubectl get job [job] -f
kubectl create job [myjob] --image=perl:5.34 -- sh -c "[command]"
kubectl logs job/[myjob]
kubectl logs pod/[myjob-pod]
k logs jobs/[myjob] --all-pods

## Cronjobs
kubectl get cj [cronjob] -o yaml
date # get current time
kubectl create cronjob my-job --image=busybox --schedule="*/1 * * * *" -- date
k logs cj/[mycj] --all-pods

## Volumes, PVCs
kubectl get pv,pvc
kubectl describe pvc [pvc] # to see why it is not binding
kubectl describe pod busybox | grep -Ei "mount|volume" -A 6

## Custom resource definitions
kubectl get crd
kubectl get crd [crd] -o yaml

## Debug and Troubleshooting
# Work from the application running inside a container to the cluster as a whole
kubectl get pods [pod] [-o yaml]
kubectl describe [resource]  # Look for an unusual number of restarts (probe issues)
kubectl get events
kubectl logs [pod] [container] -n [namespace] -f  # -f = follow
kubectl logs [pod] -p  # previous pod logs
kubectl logs [node]

# Traffic
kubectl get svc [svc] [-o yaml]
kubectl get ep [svc] [-o yaml] # endpoints

# Then networking, including DNS, firewalls and general connectivity
# RBAC can give issues: check the policies, roles and clusterbindings
cat /etc/resolv.conf

kubectl debug -h
# Deploy a debug container in a pod
kubectl debug [mypod] --image=[busybox]
kubectl describe pod | grep debugger
# Create and attach to it interactively 
kubectl debug [mypod] -it --image=[busybox]
# in a node
kubectl debug node/[node] -it --image=[busybox]
# debug a node having access to root filesystem
kubectl debug node/kind-worker2 -it --image=busybox -- chroot /host

# controllers, RBAC issues
kubectl -n kube-system get pod
kubectl -n kube-system logs kube-proxy-*

# iptables
sudo iptables-save | grep [pod]  # find the destination port
# in node
curl localhost:[PORT]

# Commands
ps
ps aux
ps -elf | grep kube-proxy
df
du -h[s]
journalctl -a
journalctl -a | grep kube-proxy
/var/log/<agent>.log  # e.g. /var/log/kube-proxy.log
# test connection to outside from inside container
nc -vz 127.0.0.1 80
nc -vz www.linux.com 80
# DNS
nslookup [mypod]
nslookup [IP]  # find FQDN of object with IP (needed for across-node lookups)


## Containers
[sudo] podman build -t [image-tag] .
podman run --name pctest --rm -idt -p 9080:8080 docker.io/jcampos15/petclinic:v1
podman image ls
podman run [image-tag]
podman image push/pull [image-tag]
podman volume ls
podman exec -it [image-tag] bash
podman logs [container-id]
poman stop [container-id]
podman rm [container-id]

## Taints
kubectl describe nodes | grep -i taint

kubectl taint --help
# Remove from node 'foo' the taint with key 'dedicated' and effect 'NoSchedule'
kubectl taint nodes foo dedicated:NoSchedule-

# Remove from node 'foo' all the taints with key 'dedicated'
kubectl taint nodes foo dedicated-
  
# Add to node 'foo' a taint with key 'bar' and no value
kubectl taint nodes foo bar:NoSchedule

## Local registry
kubectl get svc | grep registry
repo=[registry-ip]:[registry-port]
curl $repo/v2/_catalog
podman image tag $repo/[image-tag]
podman image push $repo/[image-tag]
podman image pull $repo/[image-tag]

## Custom columns
k get pod -o yaml
k get pod -o custom-columns=NAME:.metadata.name,STATUS:.status.phase

## awk
kubectl get pods | awk '{print $1, $3}'  # first and third column
kubectl get pods | awk 'NR>1 {print $1, $3}' # without headers

kubectl get pods secondapp -o wide | awk -F'  +' '{print $1, $3}'  # fields 1 & 3
kubectl get pods -l app=try1 | awk -F'  +' 'NR> 1 {print $1, $3}'
kubectl get pods -l app=try1 --no-headers | awk -F'  +' '{print $1, $3}'
echo $(kubectl get svc | awk -F'  +' '$1 == "registry" {print $1, $3}')

## Miscelaneous
echo $?  # print the status of the last command

# NFS
showmount -e cp  # in worker node
sudo mount cp:/opt/sfw /mnt  # in worker node, mount NFS

# Kustomize
kubectl kustomize <kustomization directory>/  # get generated yaml

Run one of the following commands to view the Deployment object dev-my-nginx:

kubectl get -k ./
kubectl describe -k ./

# Run the following command to compare the Deployment object dev-my-nginx against the state that the cluster would be in if the manifest was applied:
kubectl diff -k ./

kubectl delete -k ./
